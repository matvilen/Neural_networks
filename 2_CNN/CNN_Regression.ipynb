{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a53e264-c418-411e-ad3e-b454c863a331",
   "metadata": {},
   "source": [
    "# CNN –≤ –∑–∞–¥–∞—á–µ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746860dc-da3f-4b9b-ac32-50359477e6ac",
   "metadata": {},
   "source": [
    "## –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "539700ed-3f66-401c-80c7-0a38718ac6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f123fda-a070-4213-b6da-59936aa39a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –≤—ã–±–æ—Ä –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b3c897-dfe5-45f5-bd24-0c7df923d723",
   "metadata": {},
   "source": [
    "## –ò–º–ø–æ—Ä—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4fdd14e-42e3-4688-ba6b-e1de3fe68a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\", \"_datasets\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d02286b-52c1-42aa-969a-1fb06024eb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BWSquares_ds import BWSquare_DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb22f5b7-cada-46a5-8072-21412496823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bws_transform = v2.Compose(\n",
    "    [\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(dtype = torch.float32, scale=True),\n",
    "        v2.Normalize(mean=(0.5,), std = (0.5,))\n",
    "    ]\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37a08d16-9220-4c2f-a9eb-48f3a31797a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BWSquares_ds_path = os.path.join(os.getcwd(), \"..\", \"_datasets/BWSquares\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49d9c287-173e-4dc4-b1cc-2da3bc07bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bws_dataset = BWSquare_DS(BWSquares_ds_path, transform=bws_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "efc3e180-8966-43d0-9660-86fae0387b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bws_train_data, bws_val_data, bws_test_data = random_split(bws_dataset, [0.7, 0.1, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84cea7fc-2b32-4399-af76-9f02d0538ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –±–∞—Ç—á–∏\n",
    "\n",
    "bws_train_loader = DataLoader(bws_train_data, batch_size=32, shuffle=True)\n",
    "bws_val_loader = DataLoader(bws_val_data, batch_size=32, shuffle=False)\n",
    "bws_test_loader = DataLoader(bws_test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9683292-b20e-4a97-8cf0-72067bcc7073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bws_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175b641a-55b8-4409-824f-f888a99c1b2d",
   "metadata": {},
   "source": [
    "## –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20f0bc82-1b86-4950-93e5-e5b9d4de6562",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regr_Model(nn.Module):\n",
    "    def __init__(self, in_channels, out):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, (3, 3), bias=False), # (batch_size, in_channels, 64, 64) => (batch_size, 32, 62, 62)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (3, 3), bias=False),          # (batch_size, 26, 62, 62) => (batch_size, 64, 60, 60)\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten()                         # (batch_size, 64, 60, 60) => (batch_size, 64*60*60) \n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*60*60, 128),                       # (batch_size, 128) \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, out)                             # (batch_size, out)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1cfc4875-baf6-467e-a47d-55f6189f1281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Regr_Model(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=230400, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "\n",
    "model_regression = Regr_Model(1, 2).to(device)\n",
    "model_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "666f628a-7067-4ce8-8035-9833c99cc74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, mode='min', patience=10, threshold=0.0001, threshold_mode='rel'):\n",
    "        if mode not in {'min', 'max'}:\n",
    "            raise ValueError(f\"–ü–∞—Ä–∞–º–µ—Ç—Ä mode –º–æ–∂–µ—Ç –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–µ–Ω–∏—è max –∏ min.\")\n",
    "        if threshold_mode not in {'rel', 'abs'}:\n",
    "            raise ValueError(f\"–ü–∞—Ä–∞–º–µ—Ç—Ä threshold_mode –º–æ–∂–µ—Ç –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–µ–Ω–∏—è rel –∏ abs.\")\n",
    "        if not isinstance(patience, int):\n",
    "            raise TypeError(f\"–ü–∞—Ä–∞–º–µ—Ç—Ä patience –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ü–µ–ª—ã–º —á–∏—Å–ª–æ–º.\")\n",
    "        if not isinstance(threshold, float):\n",
    "            raise TypeError(f\"–ü–∞—Ä–∞–º–µ—Ç—Ä threshold –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å float.\")\n",
    "        if threshold >= 1.0:\n",
    "            raise ValueError(f\"–ü–∞—Ä–∞–º–µ—Ç—Ä threshold –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–µ–Ω—å—à–µ 1,0.\")\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.patience = patience\n",
    "        self.threshold = threshold\n",
    "        self.threshold_mode = threshold_mode\n",
    "        self.count = 0\n",
    "        self.best = None\n",
    "\n",
    "\n",
    "    def __call__(self, tracked_parameter): # tracked_parameter - —ç—Ç–æ –ª–∏–±–æ —Ñ-—Ü–∏—è –ø–æ—Ç–µ—Ä—å, –ª–∏–±–æ –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "        current = float(tracked_parameter)\n",
    "        \n",
    "        if self.best is None:\n",
    "            self.best = current\n",
    "            return False\n",
    "        \n",
    "        if self.changed_better(current, self.best):\n",
    "            self.best = current\n",
    "            self.count = 0\n",
    "        else:\n",
    "            self.count += 1\n",
    "        \n",
    "        if self.count >= self.patience:\n",
    "            return True  # —Å–∏–≥–Ω–∞–ª –∫ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ\n",
    "        return False  # –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ\n",
    "\n",
    "\n",
    "    def changed_better(self, current, best):\n",
    "        if self.mode == 'min' and self.threshold_mode == 'rel':\n",
    "            return current < best * (1 - self.threshold)\n",
    "        elif self.mode == 'min' and self.threshold_mode == 'abs':\n",
    "            return current < best - self.threshold\n",
    "        elif self.mode == 'max' and self.threshold_mode == 'rel':\n",
    "            return current > best * (1 + self.threshold)\n",
    "        else:  # mode == 'max' and threshold_mode == 'abs'\n",
    "            return current > best + self.threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14f8f1df-835d-48d2-9beb-d4018d93fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞\n",
    "\n",
    "loss_regression = nn.MSELoss()\n",
    "opt_regression = torch.optim.Adam(model_regression.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92365639-a726-4cbf-baa5-3095108c7c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                            opt_regression,       # –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä\n",
    "                            mode='min',           # 'max' –∏–ª–∏ 'min'\n",
    "                            factor=0.1,           # –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç —É–º–Ω–æ–∂–µ–Ω lr\n",
    "                            patience=5            # –∫–æ–ª-–≤–æ —ç–ø–æ—Ö –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞\n",
    "                        )\n",
    "\n",
    "earlystopping = EarlyStopping(mode='min', patience = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7dae7c5-c475-4cdd-a9de-67cebcb8e6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –º–æ–¥–µ–ª–∏\n",
    "\n",
    "InpCheck = torch.rand([16, 1, 64, 64], dtype=torch.float32).to(device)\n",
    "\n",
    "OutCheck = model_regression(InpCheck)\n",
    "OutCheck.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af578ef-b121-4f2b-90c9-27628a89ea01",
   "metadata": {},
   "source": [
    "## –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67d2de87-d832-4820-b16f-b1827e10982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "reg_lr_list = []\n",
    "reg_best_loss = 100000\n",
    "threshold = 0.0001\n",
    "last_saved_reg_model = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c8be6f73-4d21-4029-b223-c980467c2439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Epoch: [1/30], train_loss = 1.9030, train_acc=0.7652, val_loss=0.2879, val_acc=0.3506, lr=0.0010\n",
      " –≠–ø–æ—Ö–∞ 1: —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ - 0.2879\n",
      "\n",
      " –ú–æ–¥–µ–ª—å: models/bws_model_checkpoint_epoch_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [2/30], train_loss = 0.1512:  26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                               | 567/2188 [01:52<04:56,  5.47it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Epoch: [3/30], train_loss = 0.0764, train_acc=0.8796, val_loss=0.0824, val_acc=0.8888, lr=0.0010\n",
      " –≠–ø–æ—Ö–∞ 3: —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ - 0.0824\n",
      "\n",
      " –ú–æ–¥–µ–ª—å: models/bws_model_checkpoint_epoch_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Epoch: [4/30], train_loss = 0.0690, train_acc=0.9163, val_loss=0.0305, val_acc=0.9948, lr=0.0010\n",
      " –≠–ø–æ—Ö–∞ 4: —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ - 0.0305\n",
      "\n",
      " –ú–æ–¥–µ–ª—å: models/bws_model_checkpoint_epoch_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Epoch: [5/30], train_loss = 0.0569, train_acc=0.9317, val_loss=0.0783, val_acc=0.8933, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Epoch: [6/30], train_loss = 0.0503, train_acc=0.9465, val_loss=0.1022, val_acc=0.8774, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [7/30], train_loss = 0.0510:  46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 1004/2188 [02:27<03:19,  5.95it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch: [8/30], train_loss = 0.0466:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1989/2188 [05:23<00:34,  5.80it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Epoch: [9/30], train_loss = 0.0426, train_acc=0.9637, val_loss=0.0184, val_acc=0.9992, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Epoch: [10/30], train_loss = 0.0358, train_acc=0.9785, val_loss=0.0431, val_acc=0.9821, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Epoch: [11/30], train_loss = 0.0385, train_acc=0.9669, val_loss=0.0518, val_acc=0.9717, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Epoch: [12/30], train_loss = 0.0320, train_acc=0.9837, val_loss=0.0228, val_acc=0.9971, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Epoch: [13/30], train_loss = 0.0303, train_acc=0.9855, val_loss=0.0861, val_acc=0.8781, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Epoch: [14/30], train_loss = 0.0302, train_acc=0.9873, val_loss=0.0145, val_acc=0.9989, lr=0.0010\n",
      " –≠–ø–æ—Ö–∞ 14: —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ - 0.0145\n",
      "\n",
      " –ú–æ–¥–µ–ª—å: models/bws_model_checkpoint_epoch_14.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Epoch: [15/30], train_loss = 0.0295, train_acc=0.9863, val_loss=0.0432, val_acc=0.9898, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Epoch: [16/30], train_loss = 0.0275, train_acc=0.9906, val_loss=0.0307, val_acc=0.9966, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [17/30], train_loss = 0.0251:  14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                    | 308/2188 [00:45<04:14,  7.39it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Epoch: [18/30], train_loss = 0.0288, train_acc=0.9890, val_loss=0.0203, val_acc=0.9985, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [19/30], train_loss = 0.0231:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 1087/2188 [03:45<03:33,  5.15it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch: [20/30], train_loss = 0.0257:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 1788/2188 [06:00<01:18,  5.11it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Epoch: [22/30], train_loss = 0.0232, train_acc=0.9936, val_loss=0.0231, val_acc=0.9991, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [23/30], train_loss = 0.0175:  11%|‚ñà‚ñà‚ñà‚ñà‚ñç                                     | 233/2188 [00:38<05:29,  5.93it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Epoch: [24/30], train_loss = 0.0223, train_acc=0.9945, val_loss=0.0426, val_acc=0.9896, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Epoch: [25/30], train_loss = 0.0220, train_acc=0.9957, val_loss=0.0180, val_acc=0.9979, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [26/30], train_loss = 0.0214:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2094/2188 [05:36<00:14,  6.45it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch: [30/30], train_loss = 0.0065:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 1252/2188 [03:47<03:27,  4.51it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n",
      "Epoch: [30/30], train_loss = 0.0064, train_acc=1.0000, val_loss=0.0106, val_acc=0.9999, lr=0.0001\n"
     ]
    }
   ],
   "source": [
    "# –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    #—Ä–µ–∂–∏–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏\n",
    "    model_regression.train()\n",
    "    running_train_loss = []\n",
    "    train_true_answers = 0\n",
    "    train_loop = tqdm(bws_train_loader, leave=False)\n",
    "    for x, targets in train_loop:\n",
    "        x = x.to(device)               # (batch_size, 1, 64, 64)\n",
    "        targets = targets.to(device)   # (batch_size, tensor[float, float])\n",
    "\n",
    "\n",
    "        # –ø—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ + —Ä–∞—Å—á–µ—Ç –æ—à–∏–±–∫–∏ –º–æ–¥–µ–ª–∏\n",
    "        pred = model_regression(x)\n",
    "        # pred - –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏,  target - –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã -> –ø–æ–¥–∞–µ–º –Ω–∞ –≤—Ö–æ–¥ —Ñ-—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å\n",
    "        loss = loss_regression(pred, targets)\n",
    "\n",
    "        # –æ–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥\n",
    "        opt_regression.zero_grad() #–æ–±–Ω—É–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞\n",
    "        loss.backward() # —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –±–∞—Ç—á–∞\n",
    "\n",
    "        # —à–∞–≥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n",
    "        opt_regression.step() # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –∏–∑ —à–∞–≥–∞ –≤—ã—à–µ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤–µ—Å–æ–≤\n",
    "\n",
    "        running_train_loss.append(loss.item())\n",
    "        mean_train_loss = sum(running_train_loss)/len(running_train_loss)\n",
    "\n",
    "        train_true_answers += (targets == torch.round(pred)).all(dim=1).sum().item()\n",
    "\n",
    "        train_loop.set_description(f'Epoch: [{epoch+1}/{EPOCHS}], train_loss = {mean_train_loss:.4f}') \n",
    "\n",
    "    # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫\n",
    "    train_accuracy = train_true_answers/len(bws_train_data)\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å\n",
    "    train_loss.append(mean_train_loss)\n",
    "    train_acc.append(train_accuracy)\n",
    "    \n",
    "\n",
    "    #—Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏\n",
    "    model_regression.eval()\n",
    "    with torch.no_grad():\n",
    "        running_val_loss = []\n",
    "        val_true_answers = 0\n",
    "        val_loop = tqdm(bws_val_loader, leave=False)\n",
    "        for x, targets in val_loop:\n",
    "            x = x.to(device)               # (batch_size, 1, 64, 64)\n",
    "            targets = targets.to(device)   # (batch_size, tensor[float, float])\n",
    "\n",
    "            # –ø—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ + —Ä–∞—Å—á–µ—Ç –æ—à–∏–±–∫–∏ –º–æ–¥–µ–ª–∏\n",
    "            pred = model_regression(x)\n",
    "            # pred - –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏,  target - –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã -> –ø–æ–¥–∞–µ–º –Ω–∞ –≤—Ö–æ–¥ —Ñ-—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å\n",
    "            loss = loss_regression(pred, targets)\n",
    "\n",
    "\n",
    "            running_val_loss.append(loss.item())\n",
    "            mean_val_loss = sum(running_val_loss)/len(running_val_loss)\n",
    "\n",
    "            val_loop.set_description(f'Epoch: [{epoch+1}/{EPOCHS}], train_loss = {mean_val_loss:.4f}') \n",
    "\n",
    "            val_true_answers += (targets == torch.round(pred)).all(dim=1).sum().item()\n",
    "\n",
    "        # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫\n",
    "        val_accuracy = val_true_answers / len(bws_val_data)\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å\n",
    "        val_loss.append(mean_val_loss)\n",
    "        val_acc.append(val_accuracy)\n",
    "\n",
    "    reg_lr_scheduler.step(mean_val_loss)\n",
    "    lr = reg_lr_scheduler.get_last_lr()[0]\n",
    "    reg_lr_list.append(lr)\n",
    "    print(lr)\n",
    "\n",
    "    print(f'Epoch: [{epoch+1}/{EPOCHS}], train_loss = {mean_train_loss:.4f}, train_acc={train_accuracy:.4f}, val_loss={mean_val_loss:.4f}, val_acc={val_accuracy:.4f}, lr={lr:.4f}')\n",
    "\n",
    "    if reg_best_loss is None:\n",
    "        reg_best_loss = mean_val_loss\n",
    "\n",
    "    if mean_val_loss < reg_best_loss - reg_best_loss * threshold:\n",
    "        reg_best_loss = mean_val_loss\n",
    "\n",
    "        checkpoint = {\n",
    "                        'state_model': model_regression.state_dict(),         # –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏\n",
    "                        'state_opt': opt_regression.state_dict(),             # —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞\n",
    "                        'state_lr_scheduler': reg_lr_scheduler.state_dict(),  # —Å–æ—Å—Ç–æ—è–Ω–∏–µ scheduler\n",
    "                        'loss': {                                  # –º–µ—Ç—Ä–∏–∫–∏ –ø–æ—Ç–µ—Ä—å\n",
    "                            'train_loss': train_loss,\n",
    "                            'val_loss': val_loss,\n",
    "                            'best_loss': reg_best_loss\n",
    "                        },\n",
    "                        'metric': {                                # –º–µ—Ç—Ä–∏–∫–∏ accuracy\n",
    "                            'train_acc': train_acc,\n",
    "                            'val_acc': val_acc,\n",
    "                        },\n",
    "                        'lr': reg_lr_list,                         # –∏—Å—Ç–æ—Ä–∏—è learning rate\n",
    "                        'epoch': {                                 # –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± —ç–ø–æ—Ö–∞—Ö\n",
    "                            'EPOCHS': EPOCHS,\n",
    "                            'save_epoch': epoch\n",
    "                        }\n",
    "                    }\n",
    "\n",
    "        if os.path.exists(last_saved_reg_model):\n",
    "            os.remove(last_saved_reg_model)\n",
    "        last_saved_reg_model = f'models/bws_model_checkpoint_epoch_{epoch+1}.pt'\n",
    "        torch.save(checkpoint, last_saved_reg_model)\n",
    "        \n",
    "        print(f' –≠–ø–æ—Ö–∞ {epoch+1}: —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ - {mean_val_loss:.4f}', end='\\n\\n')\n",
    "        print(f' –ú–æ–¥–µ–ª—å: {last_saved_reg_model}')\n",
    "\n",
    "    if earlystopping(mean_val_loss):\n",
    "        print(f'\\033[31m–û–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –Ω–∞ {epoch + 1} —ç–ø–æ—Ö–µ.\\033[0m')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89db5918-8ce5-4146-8dec-a1d679f51297",
   "metadata": {},
   "source": [
    "## –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15417a96-7145-4b4e-abfb-9beae134a03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss = 0.0107, test_acc=0.9998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_regression.eval()\n",
    "with torch.no_grad():\n",
    "    running_test_loss = []\n",
    "    test_true_answers = 0\n",
    "    for x, targets in bws_test_loader:\n",
    "        x = x.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # –ø—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ + —Ä–∞—Å—á–µ—Ç –æ—à–∏–±–∫–∏ –º–æ–¥–µ–ª–∏\n",
    "        pred = model_regression(x)\n",
    "        loss = loss_regression(pred, targets)\n",
    "        \n",
    "        running_test_loss.append(loss.item())\n",
    "        mean_test_loss = sum(running_test_loss)/len(running_test_loss)\n",
    "            \n",
    "        test_true_answers += (targets == torch.round(pred)).all(dim=1).sum().item()\n",
    "\n",
    "    # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫\n",
    "    running_test_acc = test_true_answers / len(bws_test_data)\n",
    "\n",
    "print(f'test_loss = {mean_test_loss:.4f}, test_acc={running_test_acc:.4f}', end = '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3266a7f-33f7-4eb2-a324-6551a037bb44",
   "metadata": {},
   "source": [
    "## –í—ã–≤–æ–¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524de74b-a5a9-4980-be4e-45e121d9da5a",
   "metadata": {},
   "source": [
    "**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –Ω–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ:**\n",
    "\n",
    "‚úÖ **–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞ –∑–∞ 30 —ç–ø–æ—Ö**, –Ω–∞–∏–ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∫–∞–∑–∞–ª–∞ –º–æ–¥–µ–ª—å **bws_model_checkpoint_epoch_27**\n",
    "\n",
    "üìä **–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞:**\n",
    "- **–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:** 99.98% (`test_acc=0.9998`)\n",
    "- **–û—à–∏–±–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:** 0.0107 (`test_loss=0.0107`)\n",
    "\n",
    "üõ† **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è:**\n",
    "- **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:** –°–≤–µ—Ä—Ç–æ—á–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å (PyTorch)\n",
    "- **–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å:** `MSELoss`\n",
    "- **–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä:** Adam —Å –Ω–∞—á–∞–ª—å–Ω—ã–º learning rate 0.001\n",
    "- **–ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ LR:** `ReduceLROnPlateau` (—É–º–µ–Ω—å—à–∞–µ—Ç LR –≤ 10 —Ä–∞–∑ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ —É–ª—É—á—à–µ–Ω–∏–π 5 —ç–ø–æ—Ö)\n",
    "- **–†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞:** –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫—É –Ω–∞ 10-–π —ç–ø–æ—Ö–µ –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏–π, –Ω–µ –±—ã–ª–æ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π\n",
    "\n",
    "üíæ **–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –Ω–∞ 27-–π —ç–ø–æ—Ö–µ** —Å —É—á–µ—Ç–æ–º:\n",
    "- –í–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞\n",
    "- –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –∏—Å—Ç–æ—Ä–∏–∏ learning rate\n",
    "- –ú–µ—Ç—Ä–∏–∫ –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "\n",
    "**–í—ã–≤–æ–¥:** –ú–æ–¥–µ–ª—å –±–µ–∑–æ—à–∏–±–æ—á–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ü–µ–Ω—Ç—Ä–∞ –±–µ–ª–æ–≥–æ –∫–≤–∞–¥—Ä–∞—Ç–∞ –±–æ–ª–µ–µ, —á–µ–º –≤ 99% —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö. <br>\n",
    "           –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ –±—ã–ª–æ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–æ –ø—Ä–∏ –ø–æ–º–æ—â–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c5d66-1be5-48cd-8b61-24baea9d19f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
